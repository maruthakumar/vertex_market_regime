#!/usr/bin/env python3
"""
TV Parallel Processor Test Runner
Validates parallel processing implementation with REAL data and performance benchmarks
NO MOCK DATA - ONLY REAL INPUT SHEETS AND HEAVYDB VALIDATION
"""

import sys
import time
import tempfile
import shutil
from pathlib import Path
from datetime import datetime

# Add current directory to path
sys.path.insert(0, '.')

def print_header(title):
    """Print formatted header"""
    print(f"\n{'='*70}")
    print(f"  {title}")
    print('='*70)

def print_test(test_name):
    """Print test name"""
    print(f"\nüß™ {test_name}")

def print_success(message):
    """Print success message"""
    print(f"   ‚úÖ {message}")

def print_error(message):
    """Print error message"""
    print(f"   ‚ùå {message}")

def print_performance(metric, value, unit, threshold=None):
    """Print performance metric"""
    threshold_text = f" (< {threshold}{unit})" if threshold else ""
    print(f"   üìä {metric}: {value:.3f}{unit}{threshold_text}")

def main():
    """Run parallel processor tests"""
    
    print_header("TV PARALLEL PROCESSOR COMPREHENSIVE TESTING")
    print(f"‚è∞ Test started: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("üîÑ Testing parallel processing with REAL configuration files")
    print("‚ö° Performance benchmarks and HeavyDB integration validation")
    print("üö´ NO MOCK DATA - Real input sheets validation only")
    
    total_start_time = time.time()
    tests_passed = 0
    tests_failed = 0
    temp_dirs = []
    
    try:
        # Import modules after path setup
        from parallel_processor import TVParallelProcessor, TVBatchProcessor
        from parser import TVParser
        
        # Test 1: Initialize parallel processor
        print_test("Testing TV Parallel Processor initialization")
        try:
            processor = TVParallelProcessor(max_workers=3)
            
            assert processor.max_workers == 3
            assert processor.total_jobs_processed == 0
            assert processor.total_processing_time == 0.0
            assert processor.failed_jobs == 0
            assert len(processor.jobs) == 0
            
            # Verify components are initialized
            assert processor.parser is not None
            assert processor.signal_processor is not None
            assert processor.query_builder is not None
            assert processor.processor is not None
            
            print_success("Parallel processor initialized successfully")
            print_success(f"Max workers: {processor.max_workers}")
            print_success("All components (parser, signal_processor, query_builder, processor) initialized")
            
            tests_passed += 1
            
        except Exception as e:
            print_error(f"Parallel processor initialization failed: {e}")
            tests_failed += 1
        
        # Test 2: Job creation with real configuration
        print_test("Testing job creation with REAL configuration files")
        try:
            base_path = Path('../../configurations/data/prod/tv')
            
            # Validate real files exist
            tv_master_path = base_path / 'TV_CONFIG_MASTER_1.0.0.xlsx'
            signals_path = base_path / 'TV_CONFIG_SIGNALS_1.0.0.xlsx'
            
            assert tv_master_path.exists(), f"TV master config not found: {tv_master_path}"
            assert signals_path.exists(), f"Signals file not found: {signals_path}"
            
            # Create temporary output directory
            temp_dir = tempfile.mkdtemp()
            temp_dirs.append(temp_dir)
            
            # Create job
            job = processor.create_job(
                job_id="test_job_real_config",
                tv_config_path=str(tv_master_path),
                signal_files=[str(signals_path)],
                output_directory=temp_dir,
                priority=1
            )
            
            # Validate job
            assert job.job_id == "test_job_real_config"
            assert job.tv_config_path == str(tv_master_path)
            assert job.signal_files == [str(signals_path)]
            assert job.output_directory == temp_dir
            assert job.status == 'pending'
            
            # Verify job is stored
            assert "test_job_real_config" in processor.jobs
            
            print_success("Job created successfully with real configuration")
            print_success(f"TV Config: {tv_master_path.name}")
            print_success(f"Signal Files: {len(job.signal_files)}")
            print_success(f"Output Directory: {temp_dir}")
            
            tests_passed += 1
            
        except Exception as e:
            print_error(f"Job creation failed: {e}")
            tests_failed += 1
        
        # Test 3: Single job processing with real data
        print_test("Testing single job processing with REAL data")
        try:
            # Process the job created above
            start_time = time.time()
            results = processor.process_job(job)
            processing_time = time.time() - start_time
            
            # Validate results
            assert isinstance(results, list)
            assert len(results) == 1  # One signal file
            
            result = results[0]
            assert result.job_id == "test_job_real_config"
            assert result.signal_file == str(signals_path)
            assert result.success is True
            assert result.processing_time > 0
            assert result.output_file is not None
            assert Path(result.output_file).exists()
            
            # Validate job status
            assert job.status == 'completed'
            assert job.start_time is not None
            assert job.end_time is not None
            assert job.results is not None
            
            # Validate job results
            job_results = job.results
            assert job_results['total_files'] == 1
            assert job_results['successful'] == 1
            assert job_results['failed'] == 0
            
            print_success("Single job processing completed successfully")
            print_success(f"Result success: {result.success}")
            print_success(f"Output file created: {Path(result.output_file).name}")
            print_performance("Processing time", processing_time, "s", 3.0)
            print_performance("Job total time", job_results['total_time'], "s")
            
            # Validate performance requirement
            assert processing_time < 3.0, f"Processing too slow: {processing_time:.3f}s"
            
            tests_passed += 1
            
        except Exception as e:
            print_error(f"Single job processing failed: {e}")
            tests_failed += 1
        
        # Test 4: Multiple signal files processing
        print_test("Testing parallel processing with multiple signal files")
        try:
            # Create multiple signal files by copying the real one
            temp_dir = tempfile.mkdtemp()
            temp_dirs.append(temp_dir)
            
            signals_dir = Path(temp_dir) / "signals"
            signals_dir.mkdir()
            output_dir = Path(temp_dir) / "output"
            output_dir.mkdir()
            
            # Create 4 signal files for parallel testing
            signal_files = []
            for i in range(4):
                signal_copy = signals_dir / f"TV_SIGNALS_COPY_{i+1}.xlsx"
                shutil.copy2(signals_path, signal_copy)
                signal_files.append(str(signal_copy))
            
            # Create job with multiple files
            parallel_job = processor.create_job(
                job_id="parallel_test_job",
                tv_config_path=str(tv_master_path),
                signal_files=signal_files,
                output_directory=str(output_dir),
                priority=1
            )
            
            # Process with parallel workers
            start_time = time.time()
            parallel_results = processor.process_job(parallel_job)
            parallel_time = time.time() - start_time
            
            # Validate parallel processing
            assert len(parallel_results) == 4
            successful_results = [r for r in parallel_results if r.success]
            failed_results = [r for r in parallel_results if not r.success]
            
            assert len(successful_results) == 4
            assert len(failed_results) == 0
            
            # Validate each result
            for result in successful_results:
                assert result.job_id == "parallel_test_job"
                assert result.success is True
                assert result.output_file is not None
                assert Path(result.output_file).exists()
                assert 'signal_count' in result.metrics
                assert result.metrics['signal_count'] == 4  # Each copy has 4 signals
            
            print_success("Parallel processing completed successfully")
            print_success(f"Files processed: {len(successful_results)}")
            print_success(f"Success rate: 100%")
            print_performance("Parallel processing time", parallel_time, "s", 5.0)
            print_performance("Average per file", parallel_time/4, "s")
            
            # Validate performance
            assert parallel_time < 5.0, f"Parallel processing too slow: {parallel_time:.3f}s"
            
            tests_passed += 1
            
        except Exception as e:
            print_error(f"Parallel processing failed: {e}")
            tests_failed += 1
        
        # Test 5: Batch processor functionality
        print_test("Testing TV Batch Processor with REAL data")
        try:
            batch_processor = TVBatchProcessor(max_workers=3)
            
            # Use the multiple signal files from previous test
            start_time = time.time()
            summary = batch_processor.process_signal_files_batch(
                tv_config_path=str(tv_master_path),
                signal_files=signal_files[:3],  # Use 3 files
                output_directory=str(output_dir)
            )
            batch_time = time.time() - start_time
            
            # Validate batch summary
            assert isinstance(summary, dict)
            assert summary['total_files'] == 3
            assert summary['successful'] == 3
            assert summary['failed'] == 0
            assert summary['success_rate'] == 100.0
            assert summary['total_processing_time'] > 0
            assert len(summary['output_files']) == 3
            assert len(summary['errors']) == 0
            
            # Validate output files exist
            for output_file in summary['output_files']:
                assert Path(output_file).exists()
            
            print_success("Batch processor completed successfully")
            print_success(f"Batch success rate: {summary['success_rate']}%")
            print_success(f"Output files generated: {len(summary['output_files'])}")
            print_performance("Batch processing time", batch_time, "s", 4.0)
            print_performance("Average per file", summary['average_processing_time'], "s")
            
            tests_passed += 1
            
        except Exception as e:
            print_error(f"Batch processor failed: {e}")
            tests_failed += 1
        
        # Test 6: Directory batch processing
        print_test("Testing directory batch processing")
        try:
            # Create a directory with signal files
            dir_temp = tempfile.mkdtemp()
            temp_dirs.append(dir_temp)
            
            dir_signals = Path(dir_temp) / "signals"
            dir_signals.mkdir()
            dir_output = Path(dir_temp) / "output"
            dir_output.mkdir()
            
            # Create signal files in directory
            for i in range(3):
                signal_copy = dir_signals / f"DIR_SIGNALS_{i+1}.xlsx"
                shutil.copy2(signals_path, signal_copy)
            
            # Process directory
            dir_summary = batch_processor.process_directory_batch(
                tv_config_path=str(tv_master_path),
                signal_directory=str(dir_signals),
                output_directory=str(dir_output),
                file_pattern="*.xlsx"
            )
            
            # Validate directory processing
            assert dir_summary['total_files'] == 3
            assert dir_summary['successful'] == 3
            assert dir_summary['failed'] == 0
            assert dir_summary['success_rate'] == 100.0
            
            print_success("Directory batch processing completed")
            print_success(f"Files found in directory: {dir_summary['total_files']}")
            print_success(f"Directory processing success rate: {dir_summary['success_rate']}%")
            
            tests_passed += 1
            
        except Exception as e:
            print_error(f"Directory batch processing failed: {e}")
            tests_failed += 1
        
        # Test 7: Performance statistics tracking
        print_test("Testing performance statistics and job management")
        try:
            # Get performance stats after all processing
            stats = processor.get_performance_stats()
            
            # Validate stats
            assert stats['total_jobs_processed'] >= 2  # At least 2 jobs processed
            assert stats['total_processing_time'] > 0
            assert stats['success_rate'] >= 0
            assert stats['average_job_time'] > 0
            assert stats['active_workers'] == 3
            
            # Test job status retrieval
            job_status = processor.get_job_status("test_job_real_config")
            assert job_status is not None
            assert job_status.status == 'completed'
            
            # Test all jobs retrieval
            all_jobs = processor.get_all_jobs()
            assert len(all_jobs) >= 2
            
            print_success("Performance statistics validated")
            print_success(f"Total jobs processed: {stats['total_jobs_processed']}")
            print_success(f"Success rate: {stats['success_rate']:.1f}%")
            print_performance("Average job time", stats['average_job_time'], "s")
            print_performance("Total processing time", stats['total_processing_time'], "s")
            
            tests_passed += 1
            
        except Exception as e:
            print_error(f"Performance statistics failed: {e}")
            tests_failed += 1
        
        # Test 8: Error handling validation
        print_test("Testing error handling with invalid files")
        try:
            error_temp = tempfile.mkdtemp()
            temp_dirs.append(error_temp)
            
            # Create invalid signal file
            invalid_file = Path(error_temp) / "invalid_signals.xlsx"
            invalid_file.write_text("This is not a valid Excel file")
            
            # Mix valid and invalid files
            mixed_files = [str(signals_path), str(invalid_file)]
            
            error_job = processor.create_job(
                job_id="error_handling_job",
                tv_config_path=str(tv_master_path),
                signal_files=mixed_files,
                output_directory=error_temp,
                priority=1
            )
            
            # Process with errors
            error_results = processor.process_job(error_job)
            
            # Validate error handling
            assert len(error_results) == 2
            successful = [r for r in error_results if r.success]
            failed = [r for r in error_results if not r.success]
            
            assert len(successful) == 1  # Valid file processed
            assert len(failed) == 1      # Invalid file failed
            
            # Validate failed result has error message
            failed_result = failed[0]
            assert failed_result.error_message is not None
            assert failed_result.output_file is None
            
            print_success("Error handling validated successfully")
            print_success(f"Valid files processed: {len(successful)}")
            print_success(f"Invalid files handled: {len(failed)}")
            print_success("Error messages captured for failed files")
            
            tests_passed += 1
            
        except Exception as e:
            print_error(f"Error handling test failed: {e}")
            tests_failed += 1
    
    finally:
        # Cleanup temporary directories
        for temp_dir in temp_dirs:
            try:
                if Path(temp_dir).exists():
                    shutil.rmtree(temp_dir)
            except Exception as e:
                print(f"Warning: Could not cleanup {temp_dir}: {e}")
    
    # Final summary
    total_time = time.time() - total_start_time
    
    print_header("PARALLEL PROCESSOR TEST RESULTS")
    print(f"‚è±Ô∏è  Total execution time: {total_time:.3f} seconds")
    print(f"‚úÖ Tests passed: {tests_passed}")
    print(f"‚ùå Tests failed: {tests_failed}")
    print(f"üìä Success rate: {(tests_passed/(tests_passed+tests_failed)*100):.1f}%")
    
    if tests_failed == 0:
        print("\nüéâ ALL PARALLEL PROCESSOR TESTS PASSED!")
        print("‚úÖ TV Parallel Processor fully validated with REAL data")
        print("‚úÖ Multiple signal files processing working perfectly")
        print("‚úÖ Batch processing functionality confirmed")
        print("‚úÖ Directory scanning and processing validated")
        print("‚úÖ Performance requirements met")
        print("‚úÖ Error handling working correctly")
        print("‚úÖ Statistics tracking functioning properly")
        print("üö´ NO MOCK DATA used - 100% real configuration validation")
        
        print("\nüìã PARALLEL PROCESSING SUMMARY:")
        print(f"   ‚Ä¢ Max Workers: {processor.max_workers}")
        print(f"   ‚Ä¢ Total Jobs Processed: {processor.total_jobs_processed}")
        print(f"   ‚Ä¢ Performance: All operations < required thresholds")
        print(f"   ‚Ä¢ Error Handling: Graceful failure recovery")
        print(f"   ‚Ä¢ Real Data: 100% validation with production files")
        
        print("\nüöÄ READY FOR:")
        print("   ‚Ä¢ Golden format output validation")
        print("   ‚Ä¢ End-to-end workflow testing")
        print("   ‚Ä¢ Production deployment")
        print("   ‚Ä¢ Integration with unified configuration system")
        
        return 0
    else:
        print(f"\n‚ö†Ô∏è  {tests_failed} TEST(S) FAILED!")
        print("Please review the errors above and fix issues before proceeding.")
        return 1

if __name__ == "__main__":
    exit_code = main()
    sys.exit(exit_code)