# Training Pipeline Configuration for Market Regime Models
# Vertex AI Pipelines (KFP v2) Configuration

# Project Configuration
project:
  project_id: "arched-bot-269016"
  location: "us-central1"
  staging_bucket: "vertex-mr-data"
  artifact_bucket: "vertex-mr-artifacts"
  
# Data Configuration
data:
  source:
    type: "bigquery"
    project: "arched-bot-269016"
    dataset: "market_regime_dev"
    table: "training_dataset"
    full_table_id: "arched-bot-269016.market_regime_dev.training_dataset"
  
  splits:
    train_ratio: 0.7
    validation_ratio: 0.2
    test_ratio: 0.1
    
  preprocessing:
    output_format: "parquet"  # parquet or tfrecords
    feature_engineering: true
    normalization: true
    handle_missing: "median_fill"
    
  quality_checks:
    min_samples: 10000
    max_missing_ratio: 0.1
    feature_count_validation: true
    target_distribution_check: true

# Model Configuration
models:
  baseline_models:
    - name: "tabnet"
      enabled: true
      hyperparameters:
        n_d: 64
        n_a: 64
        n_steps: 5
        gamma: 1.3
        lambda_sparse: 0.001
        optimizer_fn: "Adam"
        optimizer_params:
          lr: 0.02
        scheduler_params:
          step_size: 50
          gamma: 0.9
        mask_type: "entmax"
        batch_size: 1024
        max_epochs: 200
        patience: 20
        
    - name: "xgboost"
      enabled: true
      hyperparameters:
        max_depth: 6
        learning_rate: 0.1
        n_estimators: 1000
        subsample: 0.8
        colsample_bytree: 0.8
        reg_alpha: 0.1
        reg_lambda: 0.1
        objective: "multi:softprob"
        eval_metric: "mlogloss"
        early_stopping_rounds: 50
        
    - name: "lstm"
      enabled: true
      hyperparameters:
        hidden_size: 128
        num_layers: 2
        dropout: 0.2
        learning_rate: 0.001
        batch_size: 64
        sequence_length: 60
        epochs: 100
        patience: 15
        
    - name: "temporal_fusion_transformer"
      enabled: false  # Optional advanced model
      hyperparameters:
        hidden_size: 128
        attention_heads: 4
        dropout: 0.1
        learning_rate: 0.001
        batch_size: 64
        max_epochs: 100

# Training Configuration
training:
  experiment_name: "market-regime-training"
  run_prefix: "mr-train"
  
  compute:
    machine_type: "n1-highmem-8"
    accelerator_type: "NVIDIA_TESLA_T4"
    accelerator_count: 1
    
  resources:
    cpu_limit: "8"
    memory_limit: "32Gi"
    timeout_hours: 6
    
  parallel_training: true
  max_parallel_models: 3

# Evaluation Configuration
evaluation:
  metrics:
    classification:
      - "accuracy"
      - "precision"
      - "recall"
      - "f1_score"
      - "auroc"
      - "auprc"
      - "confusion_matrix"
      
    forecasting:  # For transition forecasting models
      - "mae"
      - "mse"
      - "rmse"
      - "mape"
      - "directional_accuracy"
      
    regime_specific:
      - "regime_accuracy"
      - "transition_detection_f1"
      - "regime_stability_score"
      
  validation:
    cross_validation: false  # Time series data - use time-based split
    min_accuracy_threshold: 0.75
    max_overfitting_threshold: 0.05
    
  visualization:
    confusion_matrix: true
    feature_importance: true
    learning_curves: true
    prediction_distribution: true

# Model Registry Configuration
model_registry:
  display_name_prefix: "market-regime"
  description_template: "Market regime prediction model - {model_type} trained on {dataset}"
  
  metadata:
    framework: "vertex_ai"
    version: "v1.0"
    training_framework: "kfp_v2"
    
  serving_config:
    enable_automatic_deployment: false  # Manual deployment in Epic 3
    prediction_format: "json"
    
  versioning:
    auto_increment: true
    version_prefix: "v"

# Experiment Tracking Configuration
experiments:
  vertex_ai_experiments:
    experiment_name: "market-regime-experiments"
    run_name_prefix: "mr-run"
    
  tracking:
    log_hyperparameters: true
    log_metrics: true
    log_artifacts: true
    log_model_artifacts: true
    
  metadata:
    team: "ml-engineering"
    project: "market-regime-master"
    environment: "development"

# Pipeline Orchestration Configuration
pipeline:
  name: "market-regime-training-pipeline"
  display_name: "Market Regime Training Pipeline"
  description: "Complete training pipeline for market regime prediction models"
  
  scheduling:
    enabled: false  # Manual triggering initially
    cron_schedule: "0 2 * * 0"  # Weekly on Sunday at 2 AM
    timezone: "UTC"
    
  notifications:
    email_on_failure: true
    email_recipients:
      - "ml-team@company.com"
    slack_webhook: null
    
  retry_policy:
    max_retries: 2
    retry_delay_seconds: 300
    
  monitoring:
    enable_monitoring: true
    alert_on_failure: true
    performance_tracking: true

# Environment-Specific Overrides
environments:
  development:
    data:
      source:
        dataset: "market_regime_dev"
    training:
      compute:
        machine_type: "n1-standard-4"
        accelerator_count: 0
      
  staging:
    data:
      source:
        dataset: "market_regime_staging"
    training:
      experiment_name: "market-regime-staging"
      
  production:
    data:
      source:
        dataset: "market_regime_prod"
    training:
      experiment_name: "market-regime-production"
      compute:
        machine_type: "n1-highmem-16"
        accelerator_count: 2
    pipeline:
      scheduling:
        enabled: true
      notifications:
        email_on_failure: true

# Feature Engineering Configuration
feature_engineering:
  enable_component_features: true
  
  components:
    component_01_triple_straddle:
      enabled: true
      feature_count: 89
      
    component_02_greeks_sentiment:
      enabled: true
      feature_count: 76
      gamma_weight: 1.5  # Critical parameter
      
    component_03_oi_pa_trending:
      enabled: true
      feature_count: 134
      
    component_04_iv_skew:
      enabled: true
      feature_count: 98
      
    component_05_atr_ema_cpr:
      enabled: true
      feature_count: 87
      
    component_06_correlation:
      enabled: true
      feature_count: 156
      requires_gpu: true
      
    component_07_support_resistance:
      enabled: true
      feature_count: 76
      
    component_08_master_integration:
      enabled: true
      feature_count: 58
      
  total_features: 774
  
  validation:
    feature_consistency_check: true
    parity_validation: true
    feature_importance_tracking: true

# Data Pipeline Configuration
data_pipeline:
  bigquery_to_training:
    chunk_size: 10000
    parallel_processing: true
    worker_count: 4
    
  feature_store_integration:
    online_features: 32
    offline_tables: 8
    sync_validation: true
    
  data_versioning:
    enable_versioning: true
    version_format: "YYYY-MM-DD-HH-MM"
    retention_days: 90
    
  quality_monitoring:
    enable_monitoring: true
    drift_detection: true
    anomaly_detection: true
    data_validation_rules: true

# Security Configuration
security:
  service_account: "vertex-ai-sa@arched-bot-269016.iam.gserviceaccount.com"
  
  iam_permissions:
    - "roles/aiplatform.user"
    - "roles/bigquery.dataViewer"
    - "roles/storage.objectAdmin"
    - "roles/logging.logWriter"
    
  data_encryption:
    in_transit: true
    at_rest: true
    kms_key: null  # Use default encryption
    
  network_security:
    vpc_network: "default"
    private_google_access: true
    
# Cost Management
cost_management:
  budget_alerts:
    enabled: true
    daily_budget_usd: 100
    monthly_budget_usd: 2000
    
  resource_optimization:
    auto_shutdown_idle: true
    preemptible_instances: true
    spot_instances: false
    
  monitoring:
    cost_tracking: true
    resource_utilization: true

# Debugging and Development
debugging:
  enable_debug_mode: false
  verbose_logging: false
  save_intermediate_artifacts: true
  enable_profiling: false
  
development:
  local_testing: true
  sample_data_size: 1000
  fast_training_mode: false  # Reduced epochs for testing
  
# Validation Rules
validation:
  schema_validation: true
  data_quality_checks: true
  model_performance_validation: true
  parity_testing: true
  
  thresholds:
    min_training_samples: 5000
    min_validation_samples: 1000
    min_test_samples: 500
    max_training_time_hours: 4
    min_model_accuracy: 0.70